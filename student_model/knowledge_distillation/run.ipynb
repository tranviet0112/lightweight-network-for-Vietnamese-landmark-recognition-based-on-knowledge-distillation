{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run.ipynb","provenance":[],"mount_file_id":"1NbuE8cwruoFZd37pyOFtN9ZbF3ivKkEf","authorship_tag":"ABX9TyMumS87j/h7Qxrk8VodD5Jh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Wnz_BzfEEz5g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600926316388,"user_tz":-420,"elapsed":1057,"user":{"displayName":"Nam Le","photoUrl":"","userId":"04332403570491439117"}},"outputId":"0befdf6f-7304-4579-ac60-2f808cebddd9"},"source":["cd '/content/drive/My Drive/Colab Notebooks/KD_for_place365/MODEL_C_5conv_KD_ver_1FC'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/KD_for_place365/MODEL_C_5conv_KD_ver_1FC\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EF3vOjNyFLSl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1600926536055,"user_tz":-420,"elapsed":12819,"user":{"displayName":"Nam Le","photoUrl":"","userId":"04332403570491439117"}},"outputId":"00a76847-32e5-40f8-fe5a-f134427d0d74"},"source":["!python train.py --help"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2020-09-24 05:48:45.978416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","usage: train.py [-h] [--model_dir MODEL_DIR] [--restore_file RESTORE_FILE]\n","                [--data_dir DATA_DIR]\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  --model_dir MODEL_DIR\n","                        Directory containing params.json\n","  --restore_file RESTORE_FILE\n","                        Optional, name of the file in --model_dir containing\n","                        weights to reload before training\n","  --data_dir DATA_DIR   Directory dataset of place365\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lLmPl_TIFS4j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d4c9b6fc-fb87-4c99-f622-5d46a6445f59"},"source":["!python train.py --model_dir '/content/drive/My Drive/Colab Notebooks/KD_for_place365/MODEL_C_5conv_KD_ver_1FC/experiments/cnn_distill' --data_dir '/content/drive/My Drive/Colab Notebooks/KD_for_place365/final_dataset/train'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-24 05:49:02.248708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Loading the datasets...\n","- done.\n","Experiment - model version: cnn_distill\n","Starting training for 30 epoch(s)\n","First, loading the teacher model and computing its outputs...\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Finished computing teacher outputs after 602 secs..\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","Epoch 1/30\n","  0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2352: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"," 82% 82/100 [00:45<00:08,  2.01it/s, loss=0.418]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.89it/s, loss=0.409]\n","- Train metrics: accuracy: 0.050 ; loss: 0.477\n","/content/drive/My Drive/Colab Notebooks/KD_for_place365/MODEL_C_5conv_KD_ver_1FC/evaluate.py:97: UserWarning: This overload of cuda is deprecated:\n","\tcuda(torch.device device, bool async, *, torch.memory_format memory_format)\n","Consider using one of the following signatures instead:\n","\tcuda(torch.device device, bool non_blocking, *, torch.memory_format memory_format) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n","  data_batch, labels_batch = data_batch.cuda(async=True), labels_batch.cuda(async=True)\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.238 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 2/30\n"," 43% 43/100 [00:24<00:39,  1.46it/s, loss=0.340]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.90it/s, loss=0.335]\n","- Train metrics: accuracy: 0.200 ; loss: 0.353\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.357 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 3/30\n","  3% 3/100 [00:03<05:44,  3.56s/it, loss=0.306]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.91it/s, loss=0.295]\n","- Train metrics: accuracy: 0.250 ; loss: 0.370\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.466 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 4/30\n"," 61% 61/100 [00:34<00:24,  1.59it/s, loss=0.267]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:53<00:00,  1.88it/s, loss=0.264]\n","- Train metrics: accuracy: 0.400 ; loss: 0.296\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.426 ; loss: 0.000\n","Checkpoint Directory exists! \n","Epoch 5/30\n"," 23% 23/100 [00:13<00:55,  1.39it/s, loss=0.234]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.89it/s, loss=0.235]\n","- Train metrics: accuracy: 0.500 ; loss: 0.262\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.591 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 6/30\n"," 80% 80/100 [00:43<00:16,  1.21it/s, loss=0.219]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.90it/s, loss=0.219]\n","- Train metrics: accuracy: 0.550 ; loss: 0.258\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.685 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 7/30\n","  0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:53<00:00,  1.88it/s, loss=0.202]\n","- Train metrics: accuracy: 0.800 ; loss: 0.192\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.649 ; loss: 0.000\n","Checkpoint Directory exists! \n","Epoch 8/30\n","  4% 4/100 [00:02<02:09,  1.34s/it, loss=0.199]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.89it/s, loss=0.189]\n","- Train metrics: accuracy: 0.700 ; loss: 0.203\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.799 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 9/30\n"," 17% 17/100 [00:10<00:45,  1.82it/s, loss=0.166]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:52<00:00,  1.90it/s, loss=0.172]\n","- Train metrics: accuracy: 0.850 ; loss: 0.167\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.796 ; loss: 0.000\n","Checkpoint Directory exists! \n","Epoch 10/30\n","  4% 4/100 [00:03<02:23,  1.50s/it, loss=0.147]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:53<00:00,  1.88it/s, loss=0.160]\n","- Train metrics: accuracy: 0.850 ; loss: 0.154\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.848 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 11/30\n"," 96% 96/100 [00:51<00:02,  1.41it/s, loss=0.150]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","100% 100/100 [00:53<00:00,  1.89it/s, loss=0.151]\n","- Train metrics: accuracy: 0.900 ; loss: 0.135\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n","- Eval metrics : accuracy: 0.881 ; loss: 0.000\n","Checkpoint Directory exists! \n","- Found new best accuracy\n","Epoch 12/30\n"," 31% 31/100 [00:17<00:54,  1.26it/s, loss=0.141]/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"," 71% 71/100 [00:38<00:21,  1.34it/s, loss=0.141]"],"name":"stdout"}]}]}